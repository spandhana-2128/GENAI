{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzyXyamZqi79"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "0FLxM1hdtA64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEXT GENERATION**"
      ],
      "metadata": {
        "id": "AGRMiX5-xbR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = pipeline(\"text-generation\", model=\"bert-base-uncased\")\n",
        "gen(\"The future of Artificial Intelligence is\")\n"
      ],
      "metadata": {
        "id": "6fUoEcoBtA72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = pipeline(\"text-generation\", model=\"roberta-base\")\n",
        "gen(\"The future of Artificial Intelligence is\")\n"
      ],
      "metadata": {
        "id": "f4zsbCtctA_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = pipeline(\"text-generation\", model=\"facebook/bart-base\")\n",
        "gen(\"The future of Artificial Intelligence is\")\n"
      ],
      "metadata": {
        "id": "oS-i6d_htBAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MASKED LANGUAGE MODELLING**"
      ],
      "metadata": {
        "id": "DZnho9CFxfuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fill = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "fill(\"The goal of Generative AI is to [MASK] new content.\")\n"
      ],
      "metadata": {
        "id": "rJadDLfXuhd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill = pipeline(\"fill-mask\", model=\"roberta-base\")\n",
        "fill(\"The goal of Generative AI is to <mask> new content.\")\n"
      ],
      "metadata": {
        "id": "P8PPmwHquhez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill = pipeline(\"fill-mask\", model=\"facebook/bart-base\")\n",
        "fill(\"The goal of Generative AI is to <mask> new content.\")\n"
      ],
      "metadata": {
        "id": "NMr2ztqvuhjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION ANSWERING**"
      ],
      "metadata": {
        "id": "XN52IvxZxscw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline(\"question-answering\", model=\"bert-base-uncased\")\n",
        "qa({\n",
        "    \"question\": \"What are the risks?\",\n",
        "    \"context\": \"Generative AI poses significant risks such as hallucinations, bias, and deepfakes.\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "XFSlmLiStBFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline(\"question-answering\", model=\"roberta-base\")\n",
        "qa({\n",
        "    \"question\": \"What are the risks?\",\n",
        "    \"context\": \"Generative AI poses significant risks such as hallucinations, bias, and deepfakes.\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "AnWz8Tuoux_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline(\"question-answering\", model=\"facebook/bart-base\")\n",
        "qa({\n",
        "    \"question\": \"What are the risks?\",\n",
        "    \"context\": \"Generative AI poses significant risks such as hallucinations, bias, and deepfakes.\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "liwjtHfAuy3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVATION TABLE**"
      ],
      "metadata": {
        "id": "0i74tHxQxOIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Task                   | Model   | Classification (Success/Failure) | Observation (What actually happened?)                                         | Why did this happen? (Architectural Reason)                                                     |\n",
        "| ---------------------- | ------- | -------------------------------- | ----------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |\n",
        "| **Text Generation**    | BERT    | **Failure**                      | Output was random, repetitive, or failed to generate a coherent continuation. | BERT is an **Encoder-only** model trained for understanding text, not predicting the next word. |\n",
        "|  | RoBERTa | **Failure**                      | Similar to BERT; produced incoherent or incomplete output.                    | RoBERTa is also **Encoder-only** and lacks a decoder for autoregressive generation.             |\n",
        "|    | BART    | **Success**                      | Generated a fluent and meaningful continuation of the sentence.               | BART is an **Encoder–Decoder** model with a decoder trained for text generation.                |\n",
        "| **Fill-Mask (MLM)**    | BERT    | **Success**                      | Correctly predicted words like “create”, “generate”, “produce”.               | BERT is trained using **Masked Language Modeling (MLM)**, making this its primary task.         |\n",
        "|    | RoBERTa | **Success**                      | Predicted accurate and contextually relevant masked words.                    | RoBERTa is an optimized MLM-based **Encoder-only** model.                                       |\n",
        "|     | BART    | **Partial / Failure**            | Produced less accurate or inconsistent predictions.                           | BART is trained with **denoising objectives**, not explicit token-level masking.                |\n",
        "| **Question Answering** | BERT    | **Partial Success**              | Extracted relevant parts but answers were sometimes incomplete.               | BERT can do extractive QA but works best when **fine-tuned on SQuAD**.                          |\n",
        "|  | RoBERTa | **Partial Success**              | Similar behavior to BERT with slight variation in phrasing.                   | Strong encoder but **not QA fine-tuned**, leading to unstable outputs.                          |\n",
        "| | BART    | **Partial / Failure**            | Generated verbose or inaccurate answers.                                      | QA is extractive; BART is **generative**, not optimized for span extraction.                    |\n"
      ],
      "metadata": {
        "id": "425WT--TvxvB"
      }
    }
  ]
}